{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNzLLlTbupduqnR0dDz65yw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<h1>Aula final sobre algoritmos de ML nao--RNA</h1><hr>"],"metadata":{"id":"5gp7w8p_yki0"}},{"cell_type":"code","source":["class Intro(object):\n","  def __init__(self)->None:\n","    super().__init__()\n","\n","  text1 = \"Um Contra Todos [One x All] + SoftMax [Nao eh mais a Sigmoide]\"\n","  test2 = \"Retorna as probabilidades/chances de uma classe pertencer a cada uma das classes\"\n","  text3 = \"Afunçao de custo eh a soft entropy [teoria da informaçao; bits de shannon]\"\n","\n","  @classmethod\n","  def printaText(cls)->None:\n","    print(f'{cls.text1}\\n\\n{cls.test2}\\n\\n{cls.text3}\\n\\n'.upper())\n","    return None\n","  @staticmethod\n","  def teoriaBasica()->None:\n","    stt1 = '{c}'\n","    stt2 = \"\"\"\n","      Mais de duas classes para agrupar/classificar;\n","      \\n\\n\n","      Nao da pra aplicar a regressao logistica de uma maneira pura e simples \\n\\n\n","      OneHotEncoding; MultiClass !== Multilabel\\n\\n\n","      [Output eh uma unica classe --> multiclass]\n","        [ex. medcamento que um p'aciente deve tomar]\n","      [output eh associadoa mais de uma classe ---> Multilabel [ex: uma noticia pode ser associada a mais de uma categoria]]\n","        [ex. Noticia A--> Economia e Politica]\n","    \"\"\"\n","    sttf = stt1.format(c= stt2)\n","    print(sttf.upper(), end = '\\n\\n ###### \\n\\n')\n","\n","obj1 = Intro()\n","print(obj1, end = '\\n\\n')\n","Intro.printaText()\n","Intro.teoriaBasica()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"csNYKN5Ryu98","executionInfo":{"status":"ok","timestamp":1721474004074,"user_tz":180,"elapsed":289,"user":{"displayName":"Rodrigo","userId":"04413959195006585420"}},"outputId":"9aeef25f-fee3-4529-f39f-11374c9a273f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.Intro object at 0x7a5ae7765e10>\n","\n","UM CONTRA TODOS [ONE X ALL] + SOFTMAX [NAO EH MAIS A SIGMOIDE]\n","\n","RETORNA AS PROBABILIDADES/CHANCES DE UMA CLASSE PERTENCER A CADA UMA DAS CLASSES\n","\n","AFUNÇAO DE CUSTO EH A SOFT ENTROPY [TEORIA DA INFORMAÇAO; BITS DE SHANNON]\n","\n","\n","\n","      MAIS DE DUAS CLASSES PARA AGRUPAR/CLASSIFICAR;\n","      \n","\n","\n","      NAO DA PRA APLICAR A REGRESSAO LOGISTICA DE UMA MANEIRA PURA E SIMPLES \n","\n","\n","      ONEHOTENCODING; MULTICLASS !== MULTILABEL\n","\n","\n","      [OUTPUT EH UMA UNICA CLASSE --> MULTICLASS]\n","        [EX. MEDCAMENTO QUE UM P'ACIENTE DEVE TOMAR]\n","      [OUTPUT EH ASSOCIADOA MAIS DE UMA CLASSE ---> MULTILABEL [EX: UMA NOTICIA PODE SER ASSOCIADA A MAIS DE UMA CATEGORIA]]\n","        [EX. NOTICIA A--> ECONOMIA E POLITICA]\n","    \n","\n"," ###### \n","\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","##TRATAMENTO DOS DADOS:\n","\n","x_numpy = np.array([2,4,3,5,7,2,9,4,10,9,4,6,1,5,6,9,8,3,1,5,6,5,2,7,8,2,5,9,10,2,1,3,8,5,6,5])\n","y_numpy = np.array([0,0,0,1,2,0,2,0,2,2,0,1,0,1,1,2,1,0,0,1,1,1,0,2,2,0,1,2,2,0,0,0,2,1,1,1])\n","\n","x = torch.from_numpy(x_numpy.astype(np.float32))\n","y = torch.from_numpy(y_numpy.astype(np.float32))\n","y = y.long()\n","x = x.view(x.shape[0],1)\n","\n","print(x.shape)\n","print(y.shape)\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4_3Fu7j2NwD","executionInfo":{"status":"ok","timestamp":1721474601905,"user_tz":180,"elapsed":5123,"user":{"displayName":"Rodrigo","userId":"04413959195006585420"}},"outputId":"c8b6c6ba-6293-4f38-fdcb-84cf2e50eb63"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([36, 1])\n","torch.Size([36])\n","tensor([0, 0, 0, 1, 2, 0, 2, 0, 2, 2, 0, 1, 0, 1, 1, 2, 1, 0, 0, 1, 1, 1, 0, 2,\n","        2, 0, 1, 2, 2, 0, 0, 0, 2, 1, 1, 1])\n"]}]},{"cell_type":"code","source":["##criaçao do modelo\n","\n","class RegressaoSoftmax(nn.Module):\n","  def __init__(self, n_input, n_output)->None:\n","    super(RegressaoSoftmax, self).__init__()\n","    self.Linear = nn.Linear(n_input, n_output)\n","  def foward(self, x):\n","    return self.Linear(x)\n","\n","#DEFINIÇAO DE MODELO\n","\n","input_size = 1\n","output_size = 3\n","model = RegressaoSoftmax(input_size, output_size)\n","\n","#DEFINIÇAO DA FUNÇAO DE CUSTO E OTIMIZADOR\n","\n","learning_rate = 0.05\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n","\n","#LOOP DE TREINAMENTO\n","\n","num_epochs = 1000\n","contador_custo = []\n","\n","for epoch in range(num_epochs):\n","  y_hat = model(x)\n","  loss = criterion(y_hat, y)\n","  contador_custo.append(loss)\n","  loss.backward()\n","\n","  optimizer.step()\n","\n","  optimizer.zero_grad()\n","\n","print(\"Grafico da funçao de custo\".upper())\n","plt.plot(contador_custo, 'b')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"BNO4qhcv4pbM","executionInfo":{"status":"error","timestamp":1721475484895,"user_tz":180,"elapsed":1976,"user":{"displayName":"Rodrigo","userId":"04413959195006585420"}},"outputId":"42edb414-ed95-4773-ea85-b290c3c61c40"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NotImplementedError","evalue":"Module [RegressaoSoftmax] is missing the required \"forward\" function","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-7030f1e48ec6>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcontador_custo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mcontador_custo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \"\"\"\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Module [{type(self).__name__}] is missing the required \\\"forward\\\" function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotImplementedError\u001b[0m: Module [RegressaoSoftmax] is missing the required \"forward\" function"]}]},{"cell_type":"code","source":["teste = np.array([2,3,6,8,10])\n","t_teste = torch.from_numpy(teste.astype(np.float32))\n","t_teste = t_teste.view(t_teste.shape[0], 1)\n","\n","with torch.no_grad():\n","  predicoes = model(t_teste)\n","  print(np.argmax(predicoes, axis=1).flatten()) ##funfou mas a plotagem grafica ta uma bosta :/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8SNNmzi9zj_","executionInfo":{"status":"ok","timestamp":1721476175974,"user_tz":180,"elapsed":315,"user":{"displayName":"Rodrigo","userId":"04413959195006585420"}},"outputId":"e0898727-09fc-43c5-b14c-89f955627797"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 0, 1, 2, 2])\n"]}]},{"cell_type":"code","source":["'''\n","# RECEITA DE TREINAMENTO\n","# 1 - DESIGN DO MODELO (INPUT, OUTPUT, FORWARD PASS)\n","# 2 - DEFINIÇAO DA FUNÇÃO DE CUSTO E OTIMIZADOR\n","# 3 - LOOP DE TREINAMENTO:\n","#     - FORWARD PASS: CALCULAR A PREDIÇÃO E O CUSTO\n","#     - BACKWARPASS: CALCULAR OS GRADIENTES\n","#     - ATUALIZAR OS PESOS\n","\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# PREPARAÇÃO DOS DADOS\n","\n","# Datapoints (NOTAS)\n","x_numpy = np.array([2,4,3,5,7,2,9,4,10,9,4,6,1,5,6,9,8,3, 1, 5, 6, 5,2, 7, 8, 2,5,9, 10,2,1,3,8,5,6,5])\n","# 3 classes (0=reprovados, 1=recuperação, 2=aprovados)\n","y_numpy = np.array([0,0,0,1,2,0,2,0,2,2,0,1,0,1,1,2,1,0,0,1,1,1,0,2,2,0,1,2,2,0,0,0,2,1,1,1])\n","\n","x = torch.from_numpy(x_numpy.astype(np.float32))\n","y = torch.from_numpy(y_numpy.astype(np.float32))\n","y = y.long()\n","x = x.view(x.shape[0], 1)\n","\n","print(x.shape)\n","print(y.shape)\n","print(y)\n","\n","# CLASS DE REGRESSÃO LOGÍSTICA\n","\n","class RegressaoSoftmax(nn.Module):\n","  def __init__(self, n_input, n_output):\n","    super(RegressaoSoftmax, self).__init__()\n","    self.Linear = nn.Linear(n_input, n_output)\n","\n","  def forward(self, x):\n","    return self.Linear(x)\n","\n","\n","# DEFINICIÇÃO DE MODELO\n","input_size = 1\n","output_size = 3\n","model = RegressaoSoftmax(input_size, output_size)\n","\n","# DEFINIÇÃO DA FUNÇAO DE CUSTO E OTIMIZADOR\n","learning_rate = 0.05\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","# LOOP DE TREINAMENTO\n","num_epochs = 1000\n","contador_custo = []\n","for epoch in range(num_epochs):\n","  #forward pass and loos\n","  y_hat = model(x)\n","  loss = criterion(y_hat, y)\n","  contador_custo.append(loss)\n","  #print(y_hat)\n","\n","  #backward pass (calcular gradientes)\n","  loss.backward()\n","\n","  #update (atualizar os pesos)\n","  optimizer.step()\n","\n","\n","  #limpar o otimizador\n","  optimizer.zero_grad()\n","\n","\n","#contador_custo.detach().numpy()\n","# PLOTANDO O GRÁFICO DA FUNÇÃO DE CUSTO\n","print(\"GRÁFICO DA FUNÇÃO DE CUSTO\")\n","plt.plot(contador_custo.detach(), 'b')\n","plt.show()\n","\n","\"\"\"#Fazer a predição\"\"\"\n","\n","# fazer predição de teste\n","teste = np.array([4, 9, 7, 2,6])\n","t_teste = torch.from_numpy(teste.astype(np.float32))\n","t_teste = t_teste.view(t_teste.shape[0], 1)\n","\n","with torch.no_grad():\n","  predicoes = model(t_teste)\n","  print (np.argmax(predicoes, axis=1).flatten())\n","'''\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"etSEx5N98hcx","executionInfo":{"status":"error","timestamp":1721475908736,"user_tz":180,"elapsed":926,"user":{"displayName":"Rodrigo","userId":"04413959195006585420"}},"outputId":"9a40bd49-0963-48a7-c762-0d8089f1aa74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([36, 1])\n","torch.Size([36])\n","tensor([0, 0, 0, 1, 2, 0, 2, 0, 2, 2, 0, 1, 0, 1, 1, 2, 1, 0, 0, 1, 1, 1, 0, 2,\n","        2, 0, 1, 2, 2, 0, 0, 0, 2, 1, 1, 1])\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'list' object has no attribute 'detach'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-80494e5531d6>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mcontador_custo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;31m# PLOTANDO O GRÁFICO DA FUNÇÃO DE CUSTO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GRÁFICO DA FUNÇÃO DE CUSTO\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'detach'"]}]}]}